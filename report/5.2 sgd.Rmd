<script type="text/x-mathjax-config">
MathJax.Hub.Config({
TeX: {
equationNumbers: {
autoNumber: "all",
formatNumber: function (n) {return ''+n}
}
}});</script>

```{python GradientDescent, code=readLines('../src/GradientDescent.py'), message=FALSE, warning=FALSE}
```
```{python GradientDemo, code=readLines('../src/GradientDemo.py'), message=FALSE, warning=FALSE}
```
```{python GradientFit, code=readLines('../src/GradientFit.py'), message=FALSE, warning=FALSE}
```
```{python GradientLab, code=readLines('../src/GradientLab.py'), message=FALSE, warning=FALSE}
```

```{python sgd_defaults, echo=F, eval=T}
directory = "./report/figures/SGD/Lab"
```
## Stochastic Gradient Descent 
Stochastic gradient descent (SGD), in constrast to batch gradient descent, performs a parameter update for *each* training example $x^{(i)}$ and label $y^{(i)}$:

$$\theta_j := \theta_j-\alpha \nabla_\theta J(\theta, x^{(i)};y^{(i)}).$$
On the other hand, the variance in SGD complicates the convergence and it may be difficult to determine whether the algorithm is converging each iteration. Therefore, we have to modify the way we check for convergence.  Rather than evaluating the costs after each iteration, we average the costs over a predeterimined number of observations. If the change in average costs drops below our precision threshold, we may say that the algorithm has arrived at the approximate minimum. Alternatively, we may use validation set costs, computed each $n$ observations.

### Advantages of Stochastic Gradient Descent
The primary advantages of stochastic gradient descent are time complexity for large data sets, and convergence in certain non-convex machine learning models.

#### Time Complexity
Since only one data point is used per iteration, it takes only $O(n)$ time. To process an entire epoch of stochastic gradient descent takes approximately the same amount of time as just one iteration of *batch* gradient descent. The question then becomes, which algorithm performs better, $k$ epochs of stochastic gradient descent or $k$ iterations of gradient descent. With extremely large datasets stochastic gradient descent comes out as the clear winner. Consider a dataset with 1 billion data points.  Gradient descent performs a sum over all data points to perform a single update. Stochastic gradient descent makes progress on each training example and converges much faster than gradient descent. When computational resources are the bottleneck, stochastic gradient descent is the dominant paradigm in modern large-scale machine learning.

#### Non-Convex Convergence
Optimizing a non-convex function is challenging in two respects. First, non-convex functions may have many local minima and it may be difficult to find the global minimum among them. Second, even finding a local minimum may be difficult due to the presence of saddle points which have a zero-gradient, but are not local minima. 

Let's be clear. There is no algorithm that guarantees convergence of non-convex objective functions to a global minimum. 

That said, the frequency with which SGD performs its updates results in higher variance and in additional 'noise' in the convergence path.  This randomness enables SGD to avoid some local minimums and escape some saddle points [@Ge2015]. Here's why.

![](../report/figures/Saddle_point.svg.png) 
Saddle Point. Digital Image. Nicoguaro https://commons.wikimedia.org/wiki/File:Saddle_point.svg

`r kfigr::figr(label = "saddle_point", prefix = TRUE, link = TRUE, type="Figure")`
Consider the saddle point in   `r kfigr::figr(label = "saddle_point", prefix = TRUE, link = TRUE, type="Figure")`. The key observation is that the saddle point is actually very unstable. If you were to nudge the red dot slightly in any direction, it is likely to fall off the saddle point. Stochastic gradient descent's inherent noise is the nudge that pushes the red dot off the zero gradient saddle point. 

### Challenges of Stochastic Gradient Descent


The most challenging aspect of stochastic gradient descent is selection of the learning rate. As with batch gradient descent, a learning rate that is too small will retard convergence.  One that is too large may explode the gradient or prevent the algorithm from converging all together. But the learning rate plays an additional role with SGD. Learning rates tend to suppress or amplify the inherent noise in the gradient. As such, the SGD learning rate has a greater effect on the behavior of the gradient. 

A practitioner may designate a constant learning rate, a learning rate schedule (annealing), or an adaptive learning rate. A constant learning rate, the default in the Keras SGD optimizer, requires experimentation with a range of learning rates in order to achieve suitable performance. Learning rate schedules, such as time-based decay, step decay, and exponential decay, adjust the learning rate according to the number of iterations or epochs. The hyperperameters for the learning rate schedule must be defined a-priori. Another challenge is that the learning rate applies to all parameters during the parameter update. Adaptive learning rate methods such as Adagrad, Adadelta, RMSProp, and Adam are gradient descent optimization algorithms have performed well vis-a-vis learning rate schedule and constant learning rate methods. They will be discussed later in this series. 

Another challenge is that SGD is sequential in nature and doesn't take advantage of vectorized code optimizations. Hence classic SGD can be computationally inefficient.

In the following sections, we will review the algorithm, implement a basic stochastic gradient descent class, perform hyperparameter tuning using a gridsearch, then evaluate algorithm behavior for select hyperparameter sets. 

### Algorithm
The pseudocode for the SGD algorithm looks like this. 
```{r eval=F, echo=T, tidy=F}
randomly initialize parameters theta, 
set learning rate, maximum interations, and precision
Repeat until approximate convergence
    Randomly shuffle the training set
    For i = 1,2,.., m do:
        costs += compute_costs(data, thetas)
        grad = evaluate_gradient(data, thetas)
        thetas = thetas - learning rate * grad
return(thetas)
```
`r kfigr::figr(label = "sgd_algorithm", prefix = TRUE, link = TRUE, type="Figure")`: Stochastic Gradient Descent Algorithm

### Implementation
Our implementation will be a subclass of our GradientDescent base class created in the prior section. Before we get into the weeds, let's align on a few design considerations. 

#### GradientDescent Abstract Base Class
In case you are just joining us, the abstract base class for SGD is as follows:
```{python class_init, echo=T, eval=F}
from abc import ABC, abstractmethod
import datetime
import math
import numpy as np
import pandas as pd


class GradientDescent(ABC):
    def __init__(self):
      pass
      
    def _hypothesis(self, X, theta):
        return(X.dot(theta))
        
    def _error(self, h, y):
        return(h-y)
        
    def _cost(self, e):
        return(1/2 * np.mean(e**2))        
        
    def _gradient(self, X, e):
        return(X.T.dot(e)/X.shape[0])    
        
    def _update(self, alpha, theta, gradient):
        return(theta-(alpha * gradient))        
        
    def _finished(self, state, maxiter, precision, improvement):
        if state['iteration'] == maxiter:
            return(True)        
        if abs(state['prior']-state['current']) < precision:
            self._iter_no_change += 1
            if self._iter_no_change >= improvement:
                return(True)
            else:
                return(False)
        else:
            self._iter_no_change = 0   
            return(False)
              
    def _update_state(self,state, cross_validated, iteration, J, mse):
        state['iteration'] = iteration
        state['prior'] = state['current']
        if cross_validated:
            state['current'] = mse
        else:
            state['current'] = J
        return(state)
        
    @abstractmethod
    def fit(self):
        pass
        
```

#### SGD Methods
The SGD class will have a concrete implementation of the fit method to implement the algorithm described in `r kfigr::figr(label = "sgd_algorithm", prefix = TRUE, link = TRUE, type="Figure")`. We introduce an average parameter. If true, the costs are averaged over the 

```{python sgd_fit, echo=T, eval=F}
def fit(self, X, y, theta,  X_val=None, y_val=None, average=False,
      alpha=0.01, maxiter=0, precision=0.001, improvement=5):

    iteration = 0
    epoch = 0
    J_total = 0
    state = {'prior':1, 'current':5, 'iteration':0}
    
    # Extract data
    self._X = X
    self._y = y
    self._X_val = X_val
    self._y_val = y_val
    
    # Set cross-validated flag if validation set included 
    cross_validated = all(v is not None for v in [X_val, y_val])
    
    while not self._finished(state, maxiter, precision, improvement):
      epoch += 1            
      X, y = self._shuffle(self._X,self._y)
      J_total = 0
  
      for x_i, y_i in zip(X.values, y):
          iteration += 1
  
          h = self._hypothesis(x_i, theta)
          e = self._error(h, y_i)
          J = self._cost(e)
          J_total += J
          mse = None                                
          g = self._gradient(x_i, e)                
          theta = self._update(theta, g)
  
      if cross_validated:
          h_val = self._hypothesis(X_val, theta)
          e_val = self._error(h_val, y_val)
          mse = self._cost(e_val)                
          self._J_history_val.append(mse)
      if average:
          J = J_total / X.shape[0]            
  
      state = self._update_state(state, cross_validated, iteration, J, mse)
    return(theta)
```


The fit method:     
1. initializes counts and totals
2. iterates until finished:      
    2.1. Shuffles the dataset       
    2.2. iterates over each observation in the shuffled dataset
        2.2.1. computes hypothesis, error, cost and gradient          
        2.2.2. updates the thetas
    2.3. if cross_validated:
       2.3.1. compute cost on validation set
    2.4. if average is True:
        2.4.1. compute the average cost in training set 
    2.5. update the state   
3. return(theta)      

That's it, for the most part. The complete class definitions are available at https://github.com/DecisionScients/GradientDescent.

Next, we'll tune the hyperparameters on a validation set.

### Tuning Stochastic Gradient Descent
Like batch gradient descent, SGD is parameterized most essentially by the learning rate, $\alpha$. In this section, we will use the gridsearch technique to explore the effects of various learning rates on algorithm performance. Our implementation is also parameterized by:   

* $\theta$: Our initial guess at our parameters     
* $i_{max}$: The maximum number of iterations to execute,    
* $i_{stop}$: The number of consecutive iterations of 'non-improvement' required to stop the algorithm.   
* $\epsilon$: The tolerance or precision parameter with which objective function improvement will be evaluated. 
* average: If True, convergence is based upon the average of the costs 

To contrast the performance of SGD with BGD in the prior section, we will fix these secondary parameters to the same values from our first BGD gridsearch, with one exception. 
```{python sgd_gs_params, echo=T, eval=T}
theta = np.array([-1,-1]) 
alpha = [0.02, 0.04, 0.06, 0.08, 0.1, 0.2, 0.4, 0.6, 0.8, 1]
precision = [0.001]
improvement = [5]
maxiter = 10000
average=[True]
```

#### The Data
We will use the same data from the prior section. Our training and validation sets were randomly selected from our Ames Housing Project Training Set.  The training set is comprised of random sample of 500 observations. The remaining 960 samples make up the validation set. Our single predictor of sale price will be living area. Restricting our experiment to a single predictor will allow us to more easily visualize the algorithm's behavior. 

A small function was created to randomly sample the training data and split it into the appropriate training and validation sets.
```{python sgd_data, echo=T, eval=T}
X, X_val, y, y_val = data.demo(n=500)
```

Gradient descent is sensitive to feature scaling so let's scale our data to the range [0,1] using sklearn's preprocessing module.
```{python sgd_scale, echo=T, eval=F}
from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()
X = scaler.fit_transform(X)
X_val = scaler.fit_transform(X_val)
y = scaler.fit_transform(y)
y_val = scaler.fit_transform(y_val)
```

Now that we have our scaled data, lets run our gridsearch.

#### Gridsearch
A class,  SGDLab, was created to perform our gridsearch. Let's instantiate the class, run the gridsearch and obtain some diagnostic information. 
```{python sgd_lab, echo=T, eval=T}
lab = SGDLab()
lab.gridsearch(X=X, y=y, X_val=X_val, y_val=y_val, theta=theta, alpha=alpha, precision=precision,
               maxiter=maxiter, improvement=improvement, average=average)
sgd_summary = lab.summary()
sgd_detail = lab.get_detail()   
sgd_report_filename='Stochastic Gradient Descent Gridsearch Report.csv'
sgd_report = lab.report(directory=directory, filename=sgd_report_filename)
```

#### Learning Rate Analysis
As a first step in our analysis, let's examine the speed and accuracy with which each learning rate converges. 

```{python sgd_learning_curves, echo=F, eval=T}
lab.figure(data=sgd_detail, x='iterations', y='cost', z='alpha', 
           func=lab.lineplot, directory=directory, height=2)   
```

![](../report/figures/SGD/Lab/Stochastic Gradient DescentTraining Set Costs By Iterations and Learning Rate.png)

`r kfigr::figr(label = "sgd_learning_curve_plot", prefix = TRUE, link = TRUE, type="Figure")`: Stochastic Gradient Descent Learning Curves

Let's take a closer look at final training set costs and computation times.

```{python bgd_alpha_costs, echo=F, eval=T}
lab.figure(data=sgd_summary, x='alpha', y='final_costs',
           func=lab.barplot, directory=directory, width=0.5)   
lab.figure(data=sgd_summary, x='alpha', y='duration',
           func=lab.barplot, directory=directory, width=0.5)              
```

![](../report/figures/SGD/Lab/Stochastic Gradient DescentTraining Set Costs By Learning Rate.png){width=50%}![](../report/figures/SGD/Lab/Stochastic Gradient DescentComputation Time (ms) By Learning Rate.png){width=50%}

`r kfigr::figr(label = "sgd_cost_time", prefix = TRUE, link = TRUE, type="Figure")`: Stochastic Gradient Descent Quality and Training Time
```{r, sgd_best, echo=F, eval=T}
sgd_report = read.csv(file.path(py$directory, py$sgd_report_filename))
sgd_best = sgd_report[1,]
```

Indeed, larger learning rates within our parameter space performed better from both a quality and time perspective. In fact, our best performing learning rate was actually `r sgd_best['alpha']`. It produced a validation set final cost of `r sgd_best['final_mse']`.

Let's evaluate the convergence and fit of this solution.

#### Evaluation
The `r kfigr::figr(label = "sgd_converge", prefix = TRUE, link = TRUE, type="Figure")` visualization reveals the path of the $\theta$'s to approximate convergence. The oscillation around the minimum is emblematic of high learning rate gradient descent. Approximate convergence was obtained in 7 iterations, presenting a final training set cost $J\approx0.03$.
```{python sgd_demo, echo=F, eval=T}
alpha = sgd_report.iloc[0]['alpha']
precision = sgd_report.iloc[0]['precision']
improvement = sgd_report.iloc[0]['improvement']

if not cache:
  sgd = SGDDemo()
  sgd.fit(X=X, y=y, theta=theta, X_val=X_val, y_val=y_val, alpha=alpha, precision=precision,
          maxiter=maxiter, improvement=improvement)
  sgd.show_search(directory=directory, fps=10)
  sgd.show_fit(directory=directory, fps=10)
```

![](../report/figures/SGD/Lab/Stochastic Gradient Descent Search Plot Learning Rate 0.04.gif)

`r kfigr::figr(label = "sgd_converge", prefix = TRUE, link = TRUE, type="Figure")`: Stochastic Gradient Descent - Alpha = 1.0

So, how does the solution fit the training data? Great question!

The `r kfigr::figr(label = "sgd_fit", prefix = TRUE, link = TRUE, type="Figure")` visualization illustrates the regression line fit vis-a-vis the 500 observations in our training set.   

![](../report/figures/SGD/Lab/Stochastic Gradient Descent Fit Plot Learning Rate 0.04.gif)

`r kfigr::figr(label = "sgd_fit", prefix = TRUE, link = TRUE, type="Figure")`: Stochastic Gradient Descent Fit
