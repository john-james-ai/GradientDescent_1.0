Automatically generated by Mendeley Desktop 1.19.3
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@incollection{LeCunBOM12,
author = {LeCun, Yann and Bottou, L{\'{e}}on and Orr, Genevieve B and M{\"{u}}ller, Klaus-Robert},
booktitle = {Neural Networks: Tricks of the Trade (2nd ed.)},
editor = {Montavon, Gr{\'{e}}goire and Orr, Genevieve B and M{\"{u}}ller, Klaus-Robert},
isbn = {978-3-642-35288-1},
keywords = {BackProp Efficient},
pages = {9--48},
publisher = {Springer},
series = {Lecture Notes in Computer Science},
title = {{Efficient BackProp.}},
url = {http://dblp.uni-trier.de/db/series/lncs/lncs7700.html{\#}LeCunBOM12},
volume = {7700},
year = {2012}
}
@misc{James2017,
author = {James, Gareth and Witten, Daniela and Hastie, Trevor and Maintainer, Rob Tibshirani},
file = {::},
title = {{Data for an Introduction to Statistical Learning with Applications in R}},
url = {http://www.liacs.nl/{~}putten/library/cc2000/},
year = {2017}
}
@misc{Dayan1999,
abstract = {Unsupervised learning studies how systems can learn to represent particular input patterns in a way that reflects the statistical structure of the overall collection of input patterns. By contrast with SUPERVISED LEARNING or REINFORCEMENT LEARNING, there are no explicit target outputs or environmental evaluations associated with each input; rather the unsupervised learner brings to bear prior biases as to what aspects of the structure of the input should be captured in the output.},
author = {Dayan, Peter},
booktitle = {The MIT Encyclopedia of the Cognitive Sciences},
doi = {10.1016/j.visres.2007.07.023},
issn = {0042-6989},
keywords = {Animals,Cats,Learning,Learning: physiology,Models,Neurological,Neuronal Plasticity,Neuronal Plasticity: physiology,Neurons,Neurons: physiology,Orientation,Orientation: physiology,Photic Stimulation,Photic Stimulation: methods,Sensory Deprivation,Sensory Deprivation: physiology,Visual Cortex,Visual Cortex: physiology,Visual Perception,Visual Perception: physiology},
number = {22},
pages = {1--29},
pmid = {17850840},
title = {{Unsupervised Learning}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17850840},
urldate = {2017-09-08},
volume = {47},
year = {1999}
}
@misc{Sarle2014,
abstract = {FAQ related to re-scaling/normalising NN (and other related machine learning methods) input data. Covers both "feature" and "case" based data re-scaling.},
author = {Sarle, Warren},
keywords = {SVM,SVM{\_}features,normalisation},
title = {{Should I normalize/standardize/rescale the}},
url = {http://www.faqs.org/faqs/ai-faq/neural-nets/part2/section-16.html},
urldate = {2018-10-06},
year = {2014}
}
@article{5392560,
abstract = {Two machine-learning procedures have been investigated in some detail using the game of checkers. Enough work has been done to verify the fact that a computer can be programmed so that it will learn to play a better game of checkers than can be played by the person who wrote the program. Furthermore, it can learn to do this in a remarkably short period of time (8 or 10 hours of machine-playing time) when given only the rules of the game, a sense of direction, and a redundant and incomplete list of parameters which are thought to have something to do with the game, but whose correct signs and relative weights are unknown and unspecified. The principles of machine learning verified by these experiments are, of course, applicable to many other situations.},
author = {Samuel, A L},
doi = {10.1147/rd.33.0210},
issn = {0018-8646},
journal = {IBM Journal of Research and Development},
month = {jul},
number = {3},
pages = {210--229},
title = {{Some Studies in Machine Learning Using the Game of Checkers}},
volume = {3},
year = {1959}
}
@misc{tangent,
annote = {[Online; accessed 25-October-2018]},
author = {Wikipedia contributors},
title = {{Tangent --- Wikipedia -The Free Encyclopedia}},
url = {https://en.wikipedia.org/w/index.php?title=Tangent{\&}oldid=848826334},
year = {2018}
}
@article{Samuel,
abstract = {Two machine-learning procedures have been investigated in some detail usi!Jg the game of checkers. Enough work has been done to verify the fact that a computer can be programmed so that it will learn to playa better game of checkers than can be played by the person who wrote the program. Further-more, it can learn to do this in a remarkably short period of time (8 or 10 hours of machine-playing time) when given only the rules of the game, a sense of direction, and a redundant and incomplete list of parameters which are thought to have something to do with the game, but whose correct signs and relative weights are unknown and unspecified. The principles of machine learning verified by these 'experiments are, of course, applicable to many other situations.},
author = {Samuel, Arthur L},
file = {::},
title = {{4.3.3 Some Studies in Machine Learning Using the Game of Checkers Some Studies in Machine Learning Using the Game of Checkers}},
url = {https://www.cs.virginia.edu/{~}evans/greatworks/samuel1959.pdf}
}
@article{Dozat,
abstract = {This work aims to improve upon the recently proposed and rapidly popular-ized optimization algorithm Adam (Kingma {\&} Ba, 2014). Adam has two main components—a momentum component and an adaptive learning rate component. However, regular momentum can be shown conceptually and empirically to be in-ferior to a similar algorithm known as Nesterov's accelerated gradient (NAG). We show how to modify Adam's momentum component to take advantage of insights from NAG, and then we present preliminary evidence suggesting that making this substitution improves the speed of convergence and the quality of the learned mod-els.},
author = {Dozat, Timothy},
doi = {10.1016/j.ahj.2004.02.019},
file = {::},
issn = {00028703},
journal = {International Conference on Learning Representations (ICLR) Workshop},
number = {1},
pages = {2013--2016},
title = {{Incorporating Nesterov Momentum into Adam}},
url = {http://mattmahoney.net/dc/text8.zip https://openreview.net/pdf?id=OM0jvwB8jIp57ZJjtNEZ},
year = {2016}
}
@article{Brieman2001,
abstract = {Random forests are a combination of tree predictors such that each tree depends on the values of a random vector sampled independently and with the same distribution for all trees in the forest. The generalization error for forests converges a.s. to a limit as the number of trees in the forest becomes large. The generalization error of a forest of tree classifiers depends on the strength of the individual trees in the forest and the correlation between them. Using a random selection of features to split each node yields error rates that compare favorably to Adaboost (Y. Freund {\&} R. Schapire, Machine Learning: Proceedings of the Thirteenth International conference, * * * , 148-156), but are more robust with respect to noise. Internal estimates monitor error, strength, and correlation and these are used to show the response to increasing the number of features used in the splitting. Internal estimates are also used to measure variable importance. These ideas are also applicable to regression.},
author = {Brieman, Leo},
file = {::},
journal = {Machine learning},
keywords = {classification,ensemble,regression},
pages = {5--32},
title = {{Random Forests}},
url = {https://link.springer.com/content/pdf/10.1023/A:1010933404324.pdf https://onlinelibrary.wiley.com/doi/abs/10.1002/9781118445112.stat06520},
volume = {45},
year = {2014}
}
@article{scikit-learn,
author = {Pedregosa, F and Varoquaux, G and Gramfort, A and Michel, V and Thirion, B and Grisel, O and Blondel, M and Prettenhofer, P and Weiss, R and Dubourg, V and Vanderplas, J and Passos, A and Cournapeau, D and Brucher, M and Perrot, M and Duchesnay, E},
journal = {Journal of Machine Learning Research},
pages = {2825--2830},
title = {{Scikit-learn: Machine Learning in {\{}P{\}}ython}},
volume = {12},
year = {2011}
}
@misc{TheMathworksInc.2016,
abstract = {The MATLAB platform is optimized for solving engineering and scientific problems. The matrix-based MATLAB language is the world's most natural way to express computational mathematics.},
author = {{The Mathworks Inc.}},
booktitle = {www.mathworks.com/products/matlab},
doi = {2016-11-26},
title = {{MATLAB - MathWorks}},
url = {https://www.mathworks.com/products/matlab.html http://www.mathworks.com/products/matlab/},
urldate = {2017-09-16},
year = {2016}
}
@misc{UniversityofWash,
abstract = {This Specialization from leading researchers at the University of Washington introduces you to the exciting, high-demand field of Machine Learning. Through a series of practical case studies, you will gain applied experience in major areas of Machine Learning including Prediction, Classification, Clustering, and Information Retrieval. You will learn to analyze large and complex datasets, create systems that adapt and improve over time, and build intelligent applications that can make predictions from data.},
author = {{University of Washington}},
keywords = {Coursera,certificates,courses,education,free,mooc,online,specializations},
title = {{Machine Learning - University of Washington | Coursera}},
url = {https://www.coursera.org/specializations/machine-learning https://www.coursera.org/course/machlearning},
urldate = {2017-09-08}
}
@article{GOOD1953,
abstract = {A random sample is drawn from a population of animals of various species. (The theory may also be applied to studies of literary vocabulary, for example.) If a particular species is represented r times in the sample of size N, then r/N is not a good estimate of the population frequency, p, when r is small. Methods are given for estimating p, assuming virtually nothing about the underlying population. The estimates are expressed in terms of smoothed values of the numbers nr (r= 1, 2, 3, ...), where nr is the number of distinct species that are each represented r times in the sample. (nr may be described as ‘the frequency of the frequency r'.) Turing is acknowledged for the most interesting formula in this part of the work. An estimate of the proportion of the population represented by the species occurring in the sample is an immediate corollary. Estimates are made of measures of heterogeneity of the population, including Yule's ‘characteristic' and Shannon's ‘entropy'. Methods are then discussed that do depend on assumptions about the underlying population. It is here that most work has been done by other writers. It is pointed out that a hypothesis can give a good fit to the numbers nr but can give quite the wrong value for Yule's characteristic. An example of this is Fisher's fit to some data of Williams's on Macrolepidoptera.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {GOOD, I. J.},
doi = {10.2307/2333344},
eprint = {arXiv:1011.1669v3},
file = {::},
isbn = {9788578110796},
issn = {00063444},
journal = {Biometrika},
number = {3-4},
pages = {237--264},
pmid = {25246403},
title = {{THE POPULATION FREQUENCIES OF SPECIES AND THE ESTIMATION OF POPULATION PARAMETERS}},
url = {http://pimedios.es/wp-content/uploads/2013/06/GoodTuring1953.pdf https://academic.oup.com/biomet/article-lookup/doi/10.1093/biomet/40.3-4.237},
volume = {40},
year = {1953}
}
@misc{EatonJohn2017,
author = {{Eaton, John}, W.},
doi = {10.3169/itej.65.790},
issn = {1342-6907},
title = {{Octave}},
url = {https://www.gnu.org/software/octave/ http://ci.nii.ac.jp/naid/110009669121/ http://jlc.jst.go.jp/DN/JST.JSTAGE/itej/65.790?lang=en{\&}from=CrossRef{\&}type=abstract},
year = {2017}
}
@techreport{Bottou,
abstract = {Chapter 1 strongly advocates the stochastic back-propagation method to train neural networks. This is in fact an instance of a more general technique called stochastic gradient descent (SGD). This chapter provides background material, explains why SGD is a good learning algorithm when the training set is large, and provides useful recommendations.},
author = {Bottou, L{\'{e}}on},
file = {::},
title = {{Stochastic Gradient Descent Tricks}},
url = {http://leon.bottou.org}
}
@techreport{Ge2015,
abstract = {We analyze stochastic gradient descent for optimizing non-convex functions. In many cases for non-convex functions the goal is to find a reasonable local minimum, and the main concern is that gradient updates are trapped in saddle points. In this paper we identify strict saddle property for non-convex problem that allows for efficient optimization. Using this property we show that stochastic gradient descent converges to a local minimum in a polynomial number of iterations. To the best of our knowledge this is the first work that gives global convergence guarantees for stochastic gradient descent on non-convex functions with exponentially many local minima and saddle points. Our analysis can be applied to orthogonal tensor decomposition, which is widely used in learning a rich class of latent variable models. We propose a new optimization formulation for the tensor decomposition problem that has strict saddle property. As a result we get the first online algorithm for orthogonal tensor decomposition with global convergence guarantee.},
archivePrefix = {arXiv},
arxivId = {1503.02101v1},
author = {Ge, Rong and Huang, Furong and Jin, Chi and Yuan, Yang},
eprint = {1503.02101v1},
file = {::},
keywords = {()},
title = {{Escaping From Saddle Points-Online Stochastic Gradient for Tensor Decomposition}},
url = {https://arxiv.org/pdf/1503.02101.pdf},
year = {2015}
}
@article{Ravauta,
abstract = {Any gradient descent requires to choose a learning rate. With deeper and deeper models, tuning that learning rate can easily become tedious and does not necesarily lead to an ideal convergence. We propose a variation of the gradient descent algorithm in the which the learning rate $\eta$ is not fixed. Instead, we learn $\eta$ itself, either by another gradient descent (first-order method), or by Newton's method (second-order). This way, gradient descent for any machine learning algorithm can be optimized.},
author = {Ravaut, Mathieu},
file = {::},
title = {{Faster gradient descent via an adaptive learning rate}},
url = {http://www.cs.toronto.edu/{~}mravox/p4.pdf}
}
@book{hastie01statisticallearning,
abstract = {The area's standard text revised and expanded. During the past decade has been an explosion in computation and information technology. With it has come vast amounts of data in a variety of fields such as medicine, biology, finance, and marketing. The challenge of understanding these data has led to the development of new tools in the field of statistics, and spawned new areas such as data mining, machine learning, and bioinformatics. Many of these tools have common underpinnings but are often expressed with different terminology. This book descibes the important ideas in these areas in a common conceptual framework. While the approach is statistical, the emphasis is on concepts rather than mathematics. Many examples are given, with a liberal use of color graphics. It should be a valuable resource for statisticians and anyone interested in data mining in science or industry. The book's coverage is broad, from supervised learning (prediction) to unsupervised learning. The many topics include neural networks, support vector machines, classification trees and boosting--the first comprehensive treatment of this topic in any book. This major new edition features many topics not covered in the original, including graphical models, random forests, ensemble methods, least angle regression {\&} path algorithms for the lasso, non-negative matrix factorization and spectral clustering. There is also a chapter on methods for ``wide'' data ( p bigger than n), including multiple testing and false discovery rates. Trevor Hastie, Robert Tibshirani, and Jerome Friedman are professors of statistics at Stanford University. They are prominent researchers in this area: Hastie and Tibshirani developed generalized additive models and wrote a popular book of that title. Hastie wrote much of the statistical modeling software in S-PLUS and invented principal curves and surfaces. Tibshirani proposed the Lasso and is co-author of the very successful An Introduction to the Bootstrap. Friedman is the co-inventor of many data-mining tools including CART, MARS, and projection pursuit.},
address = {New York, NY, USA},
author = {Hastie, Trevor and Tibshirani, Robert and Friedman, Jerome},
publisher = {Springer New York Inc.},
series = {Springer Series in Statistics},
title = {{The Elements of Statistical Learning}},
year = {2001}
}
@inproceedings{1716540,
abstract = {The standard method in optimization problems consists in a random search of the global minimum: a neuron network relaxes in the nearest local minimum from some randomly chosen initial configuration. This procedure is to be repeated many times in order to find as deep energy minimum as possible. However the question about the reasonable number of such random starts and if the result of the search can be treated as successful remains always open. In this paper by analyzing the generalized Hopfield model we obtain expressions, which yield the relationship between the depth of a local minimum and the size of the basin of attraction. Based on this, we present the probability of finding a local minimum as a function of the depth of the minimum. Such a relation can be used in optimization applications: it allows one, basing on a series of already found minima, to estimate the probability of finding a deeper minimum, and decide in favor of or against further running the program. The theory is in a good agreement with experimental results.},
author = {Kryzhanovsky, Boris and Magomedov, Bashir and Fonarev, Anatoly},
booktitle = {The 2006 IEEE International Joint Conference on Neural Network Proceedings},
doi = {10.1109/IJCNN.2006.247318},
file = {:C$\backslash$:/Users/John/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Kryzhanovsky, Magomedov, Fonarev - Unknown - On the Probability of Finding Local Minima in Optimization Problems.pdf:pdf},
issn = {2161-4393},
keywords = {Hopfield neural nets,optimisation,probability,rand},
month = {jul},
pages = {3243--3248},
title = {{On the Probability of Finding Local Minima in Optimization Problems}},
url = {http://csivc.csi.cuny.edu/Anatoly.Fonarev/files/me{\_}scient/Kryzhmag{\_}On{\_}the{\_}probability{\%}5B1{\%}5D.pdf},
year = {2006}
}
@misc{matlab,
title = {{Unsupervised Learning - MATLAB {\&} Simulink}},
url = {https://www.mathworks.com/discovery/unsupervised-learning.html},
urldate = {2017-09-08}
}
@misc{Ng,
abstract = {Machine learning is the science of getting computers to act without being explicitly programmed. In the past decade, machine learning has given us self-driving cars, practical speech recognition, effective web search, and a vastly improved understanding of the human genome. Machine learning is so pervasive today that you probably use it dozens of times a day without knowing it. Many researchers also think it is the best way to make progress towards human-level AI. In this class, you will learn about the most effective machine learning techniques, and gain practice implementing them and getting them to work for yourself. More importantly, you'll learn about not only the theoretical underpinnings of learning, but also gain the practical know-how needed to quickly and powerfully apply these techniques to new problems. Finally, you'll learn about some of Silicon Valley's best practices in innovation as it pertains to machine learning and AI. This course provides a broad introduction to machine learning, datamining, and statistical pattern recognition. Topics include: (i) Supervised learning (parametric/non-parametric algorithms, support vector machines, kernels, neural networks). (ii) Unsupervised learning (clustering, dimensionality reduction, recommender systems, deep learning). (iii) Best practices in machine learning (bias/variance theory; innovation process in machine learning and AI). The course will also draw from numerous case studies and applications, so that you'll also learn how to apply learning algorithms to building smart robots (perception, control), text understanding (web search, anti-spam), computer vision, medical informatics, audio, database mining, and other areas.},
author = {Ng, Andrew},
title = {{Machine Learning by Stanford University}},
url = {https://www.coursera.org/learn/machine-learning/home/welcome},
urldate = {2017-09-08},
year = {2015}
}
@misc{KaggleInc2016,
author = {{Kaggle Inc}},
booktitle = {kaggle.com},
title = {{House Prices: Advanced Regression Techniques - Prizes}},
url = {https://www.kaggle.com/c/house-prices-advanced-regression-techniques https://www.kaggle.com/c/house-prices-advanced-regression-techniques/details/prizes},
urldate = {2018-10-29},
year = {2016}
}
@article{JamesHastie2013,
abstract = {Review From the reviews: .,."There are interesting and non-standard topics that are not usually included in a first course in measture-theoretic probability including Markov Chains and MCMC, the bootstrap, limit theorems for martingales and mixing sequences, Brownian motion and Markov processes. The material is well-suported with many end-of-chapter problems." D.L. McLeish for Short Book Reviews of the ISI, December 2006 "The reader sees not only how measure theory is used to develop probability theory, but also how probability theory is used in applications. a The discourse is delivered in a theorem proof format and thus is better suited for classroom a . The authors prose is generally well thought out a . will make an attractive choice for a two-semester course on measure and probability, or as a second course for students with a semester of measure or probability theory under their belt." (Peter C. Kiessler, Journal of the American Statistical Association, Vol. 102 (479), 2007) "The book is a well written self-contained textbook on measure and probability theory. It consists of 18 chapters. Every chapter contains many well chosen examples and ends with several problems related to the earlier developed theory (some with hints). a At the very end of the book there is an appendix collecting necessary facts from set theory, calculus and metric spaces. The authors suggest a few possibilities on how to use their book." (Kazimierz Musial, Zentralblatt MATH, Vol. 1125 (2), 2008) "The title of the book consists of the names of its two basic parts. The booka (TM)s third part is comprised of some special topics from probability theory. a The authors suggest using the book intwo-semester graduate programs in statistics or a one-semester seminar on special topics. The material of the book is standard a is clear, comprehensive and a {\~{}}without being intimidatinga (TM)." (Rimas NorvaiAa, Mathematical Reviews, Issue 2007 f) Product Description This is a graduate level textbook on measure theory and probability theory. The book can be used as a text for a two semester sequence of courses in measure theory and probability theory, with an option to include supplemental material on stochastic processes and special topics. It is intended primarily for first year Ph.D. students in mathematics and statistics although mathematically advanced students from engineering and economics would also find the book useful. Prerequisites are kept to the minimal level of an understanding of basic real analysis concepts such as limits, continuity, differentiability, Riemann integration, and convergence of sequences and series. A review of this material is included in the appendix. The book starts with an informal introduction that provides some heuristics into the abstract concepts of measure and integration theory, which are then rigorously developed. The first part of the book can be used for a standard real analysis course for both mathematics and statistics Ph.D. students as it provides full coverage of topics such as the construction of Lebesgue-Stieltjes measures on real line and Euclidean spaces, the basic convergence theorems, L p spaces, signed measures, Radon-Nikodym theorem, Lebesgue's decomposition theorem and the fundamental theorem of Lebesgue integration on R, product spaces and product measures, and Fubini-Tonelli theorems. It also provides an elementary introduction to Banach and Hilbert spaces, convolutions, Fourier series and Fourier and Plancherel transforms. Thus part I would be particularly useful for students in a typical Statistics Ph.D. program if a separate course on real analysis is not a standard requirement. Part II (chapters 6-13) provides full coverage of standard graduate level probability theory. It starts with Kolmogorov's probability model and Kolmogorov's existence theorem. It then treats thoroughly the laws of large numbers including renewal theory and ergodic theorems with applications and then weak convergence of probability distributions, characteristic functions, the Levy-Cramer continuity theorem and the central limit theorem as well as stable laws. It ends with conditional expectations and conditional probability, and an introduction to the theory of discrete time martingales. Part III (chapters 14-18) provides a modest coverage of discrete time Markov chains with countable and general state spaces, MCMC, continuous time discrete space jump Markov processes, Brownian motion, mixing sequences, bootstrap methods, and branching processes. It could be used for a topics/seminar course or as an introduction to stochastic processes. From the reviews: "...There are interesting and non-standard topics that are not usually included in a first course in measture-theoretic probability including Markov Chains and MCMC, the bootstrap, limit theorems for martingales and mixing sequences, Brownian motion and Markov processes. The material is well-suported with many end-of-chapter problems." D.L. McLeish for Short Book Reviews of the ISI, December 2006},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Gareth, James and Daniela, Witten and Trevor, Hastie and Tibshirani, Robert},
doi = {10.1016/j.peva.2007.06.006},
eprint = {arXiv:1011.1669v3},
isbn = {9780387781884},
issn = {01621459},
pmid = {10911016},
title = {{An Introduction to Statistical Learning}},
url = {https://www-bcf.usc.edu/{~}gareth/ISL/ http://books.google.com/books?id=9tv0taI8l6YC},
volume = {8},
year = {2013}
}
@book{Data2007,
abstract = {This is an introductory course in machine learning (ML) that covers the basic theory, algorithms, and applications. ML is a key technology in Big Data, and in many financial, medical, commercial, and scientific applications. It enables computational systems to adaptively improve their performance with experience accumulated from the observed data. ML has become one of the hottest fields of study today, taken up by undergraduate and graduate students from 15 different majors at Caltech. This course balances theory and practice, and covers the mathematical as well as the heuristic aspects.},
author = {Data, Learning From},
isbn = {9780471681823},
keywords = {rning from data},
title = {{LEARNING FROM DATA}},
url = {https://work.caltech.edu/telecourse},
year = {2007}
}
@book{strang09,
abstract = {Book Description: Gilbert Strang's textbooks have changed the entire approach to learning linear algebra -- away from abstract vector spaces to specific examples of the four fundamental subspaces: the column space and nullspace of A and A'. Introduction to Linear Algebra, Fourth Edition includes challenge problems to complement the review problems that have been highly praised in previous editions. The basic course is followed by seven applications: differential equations, engineering, graph theory, statistics, Fourier methods and the FFT, linear programming, and computer graphics. Thousands of teachers in colleges and universities and now high schools are using this book, which truly explains this crucial subject.},
address = {Wellesley, MA},
author = {Strang, Gilbert},
edition = {Fourth},
isbn = {9780980232714 0980232716 9780980232721 0980232724 9788175968110 8175968117},
keywords = {linear.algebra matrix strang textbook},
publisher = {Wellesley-Cambridge Press},
title = {{Introduction to Linear Algebra}},
year = {2009}
}
@book{strang2006linear,
address = {Belmont, CA},
author = {Strang, Gilbert},
isbn = {0030105676 9780030105678 0534422004 9780534422004},
keywords = {book math to{\_}READ},
publisher = {Thomson, Brooks/Cole},
title = {{Linear algebra and its applications}},
url = {http://www.amazon.com/Linear-Algebra-Its-Applications-Edition/dp/0030105676},
year = {2006}
}
@misc{wiki:supervisedlearning,
annote = {[Online; accessed 
8-September-2017
]},
author = {Wikipedia},
title = {{Supervised learning --- Wikipedia{\{},{\}} The Free Encyclopedia}},
url = {https://en.wikipedia.org/w/index.php?title=Supervised{\_}learning{\&}oldid=791408094},
year = {2017}
}
@techreport{Dauphin,
abstract = {A central challenge to many fields of science and engineering involves minimizing non-convex error functions over continuous, high dimensional spaces. Gradient descent or quasi-Newton methods are almost ubiquitously used to perform such minimizations, and it is often thought that a main source of difficulty for these local methods to find the global minimum is the proliferation of local minima with much higher error than the global minimum. Here we argue, based on results from statistical physics, random matrix theory, neural network theory, and empirical evidence, that a deeper and more profound difficulty originates from the proliferation of saddle points, not local minima, especially in high dimensional problems of practical interest. Such saddle points are surrounded by high error plateaus that can dramatically slow down learning, and give the illusory impression of the existence of a local minimum. Motivated by these arguments, we propose a new approach to second-order optimization, the saddle-free Newton method, that can rapidly escape high dimensional saddle points, unlike gradient descent and quasi-Newton methods. We apply this algorithm to deep or recurrent neural network training, and provide numerical evidence for its superior optimization performance.},
author = {Dauphin, Yann N and Pascanu, Razvan and Gulcehre, Caglar and Cho, Kyunghyun and Ganguli, Surya and Bengio, Yoshua},
file = {::},
title = {{Identifying and attacking the saddle point problem in high-dimensional non-convex optimization}},
url = {https://papers.nips.cc/paper/5486-identifying-and-attacking-the-saddle-point-problem-in-high-dimensional-non-convex-optimization.pdf}
}
@misc{wiki:unsupervisedlearning,
annote = {[Online; accessed 
8-September-2017
]},
author = {Wikipedia},
title = {{Unsupervised learning --- Wikipedia{\{},{\}} The Free Encyclopedia}},
url = {https://en.wikipedia.org/w/index.php?title=Unsupervised{\_}learning{\&}oldid=793838440},
year = {2017}
}
@misc{DeCock,
author = {{De Cock}, Dean},
title = {{House Prices: Advanced Regression Techniques | Kaggle}},
url = {https://www.kaggle.com/c/house-prices-advanced-regression-techniques{\#}description https://www.kaggle.com/jimthompson/house-prices-advanced-regression-techniques/ensemble-model-stacked-model-example/notebook},
urldate = {2017-09-16}
}
@techreport{Marti2016,
abstract = {Heuristic search procedures aimed at finding globally optimal solutions to hard combinatorial optimization problems usually require some type of diversification to overcome local optimality. One way to achieve diversification is to restart the procedure from a new solution once a region has been explored, which constitutes a multi-start procedure. In this chapter we describe the best known multi-start methods for solving optimization problems. We also describe their connections with other metaheuristic methodologies. We propose classifying these methods in terms of their use of randomization, memory and degree of rebuild. We also present a computational comparison of these methods on solving the Maximum Diversity Problem to illustrate the efficiency of the multi-start methodology in terms of solution quality and diversification power.},
author = {Mart{\'{i}}, R and Aceves, R and Le{\'{o}}n, M T and Moreno-Vega, J M and Duarte, A and Mart{\'{i}}, Rafael and Aceves, Ricardo and Le{\'{o}}n, Maria Teresa and Moreno-Vega, Jose Marcos and Duarte, Abraham},
file = {::},
title = {{Intelligent Multi-Start Methods}},
url = {https://www.uv.es/rmarti/paper/docs/multi3.pdf}
}
@article{Bivens1986,
author = {Bivens, Irl},
file = {::},
journal = {The College Mathematics Journal},
number = {2},
pages = {133--143},
title = {{What a tangent line is when it isn't a limit}},
url = {https://www.maa.org/sites/default/files/pdf/upload{\_}library/22/Polya/07468342.di020721.02p01112.pdf},
volume = {17},
year = {1986}
}
@book{savov2017no,
abstract = {Linear algebra is the foundation of science and engineering. Knowledge of linear algebra is a prerequisite for studying statistics, machine learning, computer graphics, signal processing, chemistry, economics, quantum mechanics, and countless other applications. Indeed, linear algebra offers a powerful toolbox for modelling the real world. The NO BULLSHIT guide to LINEAR ALGEBRA shows the connections between the computational techniques of linear algebra, their geometric interpretations, and the theoretical foundations. This university-level textbook contains lessons on linear algebra written in a style that is precise and concise. Each concept is illustrated through definitions, formulas, diagrams, explanations, and examples of real-world applications. Readers build their math superpowers by solving practice problems and learning to use the computer algebra system SymPy to speed up tedious matrix arithmetic tasks.},
author = {Savov, I},
isbn = {9780992001025},
publisher = {Minireference Publishing},
title = {{No Bullshit Guide to Linear Algebra}},
url = {https://books.google.com/books?id=A4WzswEACAAJ},
year = {2017}
}
@article{Ng2000,
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Ng, Andrew},
doi = {10.1111/j.1466-8238.2009.00506.x},
eprint = {arXiv:1011.1669v3},
file = {::},
isbn = {0226206807},
issn = {02660830},
journal = {CS229 Lecture notes},
number = {1},
pages = {1--3},
pmid = {21889629},
title = {{CS229 Lecture notes}},
url = {http://cs229.stanford.edu/notes/cs229-notes1.pdf http://www.stanford.edu/class/cs229/},
volume = {1},
year = {2000}
}
@book{Mitchell1997,
abstract = {Mitchell covers the field of machine learning, the study of algorithms that allow computer programs to automatically improve through experience and that automatically infer general laws from specific data. 1. Introduction -- 2. Concept Learning and the General-to-Specific Ordering -- 3. Decision Tree Learning -- 4. Artificial Neural Networks -- 5. Evaluating Hypotheses -- 6. Bayesian Learning -- 7. Computational Learning Theory -- 8. Instance-Based Learning -- 9. Genetic Algorithms -- 10. Learning Sets of Rules -- 11. Analytical Learning -- 12. Combining Inductive and Analytical Learning -- 13. Reinforcement Learning.},
author = {Mitchell, Tom M. (Tom Michael)},
isbn = {0070428077},
pages = {414},
publisher = {McGraw-Hill},
title = {{Machine Learning}},
url = {http://www.cs.cmu.edu/{~}tom/mlbook.html},
year = {1997}
}
@article{Samuel1959,
author = {Samuel, AL},
doi = {10.1147/rd.33.0210},
file = {::},
isbn = {0018-8646},
issn = {0018-8646},
journal = {IBM Journal of research and development},
number = {3},
pages = {210--229},
title = {{Some studies in machine learning using the game of checkers}},
url = {https://pdfs.semanticscholar.org/e9e6/bb5f2a04ae30d8ecc9287f8b702eedd7b772.pdf http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=5392560},
volume = {3},
year = {1959}
}
@inproceedings{Caruana,
abstract = {In this paper we perform an empirical evaluation of supervised learning on high-dimensional data. We evaluate performance on three metrics: accuracy, AUC, and squared loss and study the effect of increasing dimensionality on the performance of the learning algorithms. Our findings are consistent with previous studies for problems of relatively low dimension, but suggest that as dimensionality increases the relative performance of the learning algorithms changes. To our surprise, the method that performs consistently well across all dimensions is random forests, followed by neural nets, boosted trees, and SVMs.},
archivePrefix = {arXiv},
arxivId = {cs/9605103},
author = {Caruana, Rich and Karampatziakis, Nikos and Yessenalina, Ainur},
booktitle = {Proceedings of the 25th international conference on Machine learning - ICML '08},
doi = {10.1145/1390156.1390169},
eprint = {9605103},
file = {::},
isbn = {9781605582054},
issn = {9781605582054},
pages = {96--103},
pmid = {17255001},
primaryClass = {cs},
title = {{An empirical evaluation of supervised learning in high dimensions}},
url = {http://yann.lecun.com/exdb/mnist/ http://portal.acm.org/citation.cfm?doid=1390156.1390169},
year = {2008}
}
@article{Lagaris2008,
abstract = {We present three new stopping rules for Multistart based methods. The first uses a device that enables the determination of the coverage of the bounded search domain. The second is based on the comparison of asymptotic expectation values of observable quantities to the actually measured ones. The third offers a probabilistic estimate for the number of local minima inside the search domain. Their performance is tested and compared to that of other widely used rules on a host of test problems in the framework of Multistart.},
author = {Lagaris, I.E. and Tsoulos, I.G.},
doi = {10.1016/j.amc.2007.08.001},
file = {::},
issn = {00963003},
journal = {Applied Mathematics and Computation},
keywords = {multistart,stochastic global optimization,stopping rules},
number = {2},
pages = {622--632},
title = {{Stopping rules for box-constrained stochastic global optimization}},
url = {http://www.optimization-online.org/DB{\_}FILE/2007/07/1726.pdf http://linkinghub.elsevier.com/retrieve/pii/S0096300307008193},
volume = {197},
year = {2008}
}
@article{Hinton2012,
abstract = {Tieleman, Tijmen and Hinton, Geoffrey. Lecture 6.5-rmsprop: Divide the gradient by a running average of its recent magnitude. COURSERA: Neural Networks for Machine Learning, 4, 2012},
author = {Hinton, Geoffrey E. and Srivastava, Nitish and Swersky, Kevin},
file = {::},
journal = {COURSERA: Neural Networks for Machine Learning},
pages = {29},
title = {{Neural Networks for Machine Learning Lecture 6a Overview of mini-batch gradient descent.}},
url = {https://www.cs.toronto.edu/{~}tijmen/csc321/slides/lecture{\_}slides{\_}lec6.pdf http://www.cs.toronto.edu/{~}tijmen/csc321/slides/lecture{\_}slides{\_}lec6.pdf},
year = {2012}
}
@techreport{Zeiler,
abstract = {We present a novel per-dimension learning rate method for gradient descent called ADADELTA. The method dynamically adapts over time using only first order information and has minimal computational overhead beyond vanilla stochas-tic gradient descent. The method requires no manual tuning of a learning rate and appears robust to noisy gradient information , different model architecture choices, various data modalities and selection of hyperparameters. We show promising results compared to other methods on the MNIST digit classification task using a single machine and on a large scale voice dataset in a distributed cluster environment.},
archivePrefix = {arXiv},
arxivId = {1212.5701v1},
author = {Zeiler, Matthew D},
eprint = {1212.5701v1},
file = {::},
keywords = {Gradient Descent,Index Terms-Adaptive Learning Rates,Machine Learn-ing,Neural Networks},
title = {{ADADELTA: AN ADAPTIVE LEARNING RATE METHOD}},
url = {https://arxiv.org/pdf/1212.5701.pdf}
}
@misc{Nga,
abstract = {Machine learning is the science of getting computers to act without being explicitly programmed. In the past decade, machine learning has given us self-driving cars, practical speech recognition, effective web search, and a vastly improved understanding of the human genome. Machine learning is so pervasive today that you probably use it dozens of times a day without knowing it. Many researchers also think it is the best way to make progress towards human-level AI. In this class, you will learn about the most effective machine learning techniques, and gain practice implementing them and getting them to work for yourself. More importantly, you'll learn about not only the theoretical underpinnings of learning, but also gain the practical know-how needed to quickly and powerfully apply these techniques to new problems. Finally, you'll learn about some of Silicon Valley's best practices in innovation as it pertains to machine learning and AI.},
author = {Ng, Andrew},
title = {{Machine Learning | Coursera}},
url = {https://www.coursera.org/learn/machine-learning/home/info},
urldate = {2017-09-16}
}
@techreport{DeCock2011,
abstract = {This paper presents a data set describing the sale of individual residential property in Ames, Iowa from 2006 to 2010. The data set contains 2930 observations and a large number of explanatory variables (23 nominal, 23 ordinal, 14 discrete, and 20 continuous) involved in assessing home values. I will discuss my previous use of the Boston Housing Data Set and I will suggest methods for incorporating this new data set as a final project in an undergraduate regression course.},
author = {{De Cock}, Dean},
booktitle = {Journal of Statistics Education},
file = {::},
keywords = {Assessed Value,Group Project,Linear Models,Multiple Regression},
number = {3},
title = {{Ames, Iowa: Alternative to the Boston Housing Data as an End of Semester Regression Project}},
url = {www.amstat.org/publications/jse/v19n3/decock.pdf},
volume = {19},
year = {2011}
}
@inproceedings{atakulreka2007,
abstract = {Feedforward neural networks are particularly useful in learning a training dataset without prior knowledge. However, weight adjusting with a gradient descent may result in the local minimum problem. Repeated training with random starting weights is among the popular methods to avoid this problem, but it requires extensive computational time. This paper proposes a simultaneous training method with removal criteria to eliminate less promising neural networks, which can decrease the probability of achieving a local minimum while efficiently utilizing resources. The experimental results demonstrate the effectiveness and efficiency of the proposed training method in comparison with conventional training.},
address = {Berlin, Heidelberg},
author = {Atakulreka, Akarachai and Sutivong, Daricha},
booktitle = {AI 2007: Advances in Artificial Intelligence},
editor = {Orgun, Mehmet A and Thornton, John},
file = {:C$\backslash$:/Users/John/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Atakulreka, Sutivong - Unknown - Avoiding Local Minima in Feedforward Neural Networks by Simultaneous Learning.pdf:pdf},
isbn = {978-3-540-76928-6},
keywords = {Feedforward Neural Networks,Local Minima,Removal Criteria,Simultaneous Learning},
pages = {100--109},
publisher = {Springer Berlin Heidelberg},
title = {{Avoiding Local Minima in Feedforward Neural Networks by Simultaneous Learning}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.100.2375{\&}rep=rep1{\&}type=pdf},
year = {2007}
}
@misc{Leek,
abstract = {One of the most common tasks performed by data scientists and data analysts are prediction and machine learning. This course will cover the basic components of building and applying prediction functions with an emphasis on practical applications. The course will provide basic grounding in concepts such as training and tests sets, overfitting, and error rates. The course will also introduce a range of model based and algorithmic machine learning methods including regression, classification trees, Naive Bayes, and random forests. The course will cover the complete process of building prediction functions including data collection, feature creation, algorithms, and evaluation.},
author = {Leek, Jeff PhD and Peng, Roger D. PhD and {Caffo, Brian}, PhD},
title = {{Coursera | Practical Machine Learning | Data Science Specialization by Johns Hopkins University}},
url = {https://www.coursera.org/learn/practical-machine-learning},
urldate = {2017-09-08}
}
@article{Robbins1951,
abstract = {Let M(x) denote the expected value at level x of the response to a certain experiment. M(x) is assumed to be a monotone function of x but is unknown to the experimenter, and it is desired to find the solution x = $\theta$ of the equation M(x) = $\alpha$, where $\alpha$ is a given constant. We give a method for making successive experiments at levels x1,x2,⋯ in such a way that xn will tend to $\theta$ in probability.},
author = {Robbins, Herbert and Monro, Sutton},
doi = {10.1214/aoms/1177729586},
file = {::},
isbn = {0003-4851},
issn = {0003-4851},
journal = {The Annals of Mathematical Statistics},
number = {3},
pages = {400--407},
title = {{A Stochastic Approximation Method}},
url = {https://projecteuclid.org/download/pdf{\_}1/euclid.aoms/1177729586 http://projecteuclid.org/euclid.aoms/1177729586{\%}5Cnpapers2://publication/uuid/0E522956-F1DE-4A56-885A-E780F05A8297 http://projecteuclid.org/euclid.aoms/1177729586},
volume = {22},
year = {1951}
}
@techreport{Mcallester2000,
abstract = {Good-Turing adjustments of word frequencies are an important tool in natural language modeling. In particular, for any sample of words, there is a set of words not occuring in that sample. The total probability mass of the words not in the sample is the so-called missing mass. Good showed that the fraction of the sample consisting of words that occur only once in the sample is a nearly unbiased estimate of the missing mass. Here, we give a high-probability confidence interval for the actual missing mass. More generally, for k 0, we give a confidence interval for the true probability mass of the set of words occuring k times in the sample.},
author = {Mcallester, David and Schapire, Robert E},
file = {::},
title = {{On the Convergence Rate of Good-Turing Estimators}},
url = {http://rob.schapire.net/papers/good-turing.pdf},
year = {2000}
}
@misc{gradient,
annote = {[Online; accessed 25-October-2018]},
author = {Wikipedia},
title = {{Gradient - Wikipedia}},
url = {https://en.wikipedia.org/w/index.php?title=Camera{\_}obscura{\&}oldid=862875479},
year = {2018}
}
@techreport{DuchiJDUCHI2011,
abstract = {We present a new family of subgradient methods that dynamically incorporate knowledge of the geometry of the data observed in earlier iterations to perform more informative gradient-based learning. Metaphorically, the adaptation allows us to find needles in haystacks in the form of very predictive but rarely seen features. Our paradigm stems from recent advances in stochastic optimization and online learning which employ proximal functions to control the gradient steps of the algorithm. We describe and analyze an apparatus for adaptively modifying the proximal function , which significantly simplifies setting a learning rate and results in regret guarantees that are provably as good as the best proximal function that can be chosen in hindsight. We give several efficient algorithms for empirical risk minimization problems with common and important regu-larization functions and domain constraints. We experimentally study our theoretical analysis and show that adaptive subgradient methods outperform state-of-the-art, yet non-adaptive, subgradient algorithms.},
author = {{Duchi JDUCHI}, John and Singer, Yoram},
booktitle = {Journal of Machine Learning Research},
file = {::},
keywords = {adaptivity,online learning,stochastic convex optimization,subgradient methods},
pages = {2121--2159},
title = {{Adaptive Subgradient Methods for Online Learning and Stochastic Optimization * Elad Hazan}},
url = {http://www.jmlr.org/papers/volume12/duchi11a/duchi11a.pdf},
volume = {12},
year = {2011}
}
@article{Dick2013,
abstract = {Many machine learning problems, such as K-means, are non-convex optimization problems. Usually they are solved by performing several local searches with ran-dom initializations. How many searches should be done? Typically a fixed num-ber is performed, but how do we know it was enough? We present a new stopping rule with non-asymptotic frequentist guarantees, which, to our knowledge, no ex-isting rule has. By comparing all stopping rules on various benchmarks, we shed light on their effectiveness in machine-learning problems, including K-means and maximum marginal likelihood parameter selection.},
author = {Dick, Travis and Wong, Eric and Dann, Christoph},
file = {:C$\backslash$:/Users/John/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Dick, Wong, Dann - 2013 - How many random restarts are enough.pdf:pdf},
title = {{How many random restarts are enough ?}},
url = {https://www.cs.cmu.edu/{~}epxing/Class/10715/project-reports/DannDickWong.pdf},
year = {2013}
}
@techreport{Darken1992,
abstract = {Stochastic gradient descent is a general algorithm that includes LMS, on-line backpropagation, and adaptive k-means clustering as special cases. The standard choices of the learning rate (both adap-tive and dxed functions of time) often perform quite poorly. In contrast, our recently proposed class of $\backslash$search then converge" (STC) learning rate schedules (Darken and Moody, 1990b, 1991) display the theoretically optimal asymptotic convergence rate and a superior ability to escape from poor local minima However, the user is responsible for setting a key parameter. We propose here a new methodology for creating the rst automatically adapting learning rates that achieve the optimal rate of convergence.},
author = {Darken, Christian and Chang, Joseph and Moody, John},
file = {::},
publisher = {IEEE Press, 445 Hoes Lane},
title = {{LEARNING RATE SCHEDULES FOR FASTER STOCHASTIC GRADIENT SEARCH}},
url = {https://pdfs.semanticscholar.org/9db5/54243d7588589569aea127d676c9644d069a.pdf},
year = {1992}
}
@misc{mitchell1997machine,
author = {Mitchell, Tom M and Others},
publisher = {McGraw-Hill Boston, MA:},
title = {{Machine learning. WCB}},
year = {1997}
}
